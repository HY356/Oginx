"""
èµ„æºç›‘æ§å®¢æˆ·ç«¯æ¨¡å—
ç”¨äºè°ƒç”¨èµ„æºç›‘æ§æœåŠ¡æ£€æŸ¥æœåŠ¡å™¨èµ„æºæ˜¯å¦å……è¶³
"""

import os
import httpx
import logging
import time
from urllib.parse import urlparse
from typing import Dict, Any, Optional, Tuple
from .resource_cache_config import (
    SAME_MODEL_INTERVAL,
    MODEL_USAGE_WINDOW
)

logger = logging.getLogger(__name__)

# èµ„æºç›‘æ§æœåŠ¡ç«¯å£é…ç½®
RESOURCE_MONITOR_CPU_PORT = int(os.getenv('RESOURCE_MONITOR_CPU_PORT', '8005'))
RESOURCE_MONITOR_GPU_PORT = int(os.getenv('RESOURCE_MONITOR_GPU_PORT', '8006'))

class ResourceMonitorClient:
    """èµ„æºç›‘æ§å®¢æˆ·ç«¯"""
    
    def __init__(self, resource_monitor_port: int = None):
        """
        åˆå§‹åŒ–èµ„æºç›‘æ§å®¢æˆ·ç«¯
        
        Args:
            resource_monitor_port: èµ„æºç›‘æ§æœåŠ¡ç«¯å£ï¼ˆå·²åºŸå¼ƒï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®ï¼‰
        """
        self.resource_monitor_port = resource_monitor_port
        self.logger = logging.getLogger(__name__)
        
        # æ¨¡å‹ä½¿ç”¨å†å²è·Ÿè¸ª
        self._model_usage_history: Dict[str, float] = {}
    
    def _should_skip_resource_check(self, server_url: str, model_name: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡èµ„æºæ£€æŸ¥ï¼ˆåŸºäºæ¨¡å‹å¹¶å‘æ„ŸçŸ¥ï¼‰"""
        usage_key = f"{server_url}:{model_name}"
        last_usage_time = self._model_usage_history.get(usage_key, 0)
        current_time = time.time()
        
        # å¦‚æœç›¸åŒæ¨¡å‹åœ¨æŒ‡å®šæ—¶é—´é—´éš”å†…ä½¿ç”¨è¿‡ï¼Œè·³è¿‡èµ„æºæ£€æŸ¥
        if (current_time - last_usage_time) < SAME_MODEL_INTERVAL:
            self.logger.debug(f"è·³è¿‡èµ„æºæ£€æŸ¥: {server_url} æ¨¡å‹ {model_name} åœ¨ {SAME_MODEL_INTERVAL} ç§’å†…ä½¿ç”¨è¿‡")
            return True
        
        return False
    
    def _track_model_usage(self, server_url: str, model_name: str):
        """è®°å½•æ¨¡å‹ä½¿ç”¨å†å²"""
        usage_key = f"{server_url}:{model_name}"
        current_time = time.time()
        self._model_usage_history[usage_key] = current_time
        
        # æ¸…ç†è¿‡æœŸçš„ä½¿ç”¨å†å²ï¼ˆè¶…è¿‡çª—å£æ—¶é—´çš„è®°å½•ï¼‰
        expired_keys = []
        for key, timestamp in self._model_usage_history.items():
            if (current_time - timestamp) > MODEL_USAGE_WINDOW:
                expired_keys.append(key)
        
        for key in expired_keys:
            del self._model_usage_history[key]
        
        self.logger.debug(f"è®°å½•æ¨¡å‹ä½¿ç”¨: {usage_key} åœ¨ {current_time}")
    
    def _convert_url_to_resource_monitor(self, server_url: str, server_type: str = "CPU") -> str:
        """å°†æœåŠ¡å™¨URLè½¬æ¢ä¸ºèµ„æºç›‘æ§æœåŠ¡URL"""
        try:
            parsed = urlparse(server_url)
            # æ ¹æ®æœåŠ¡å™¨ç±»å‹é€‰æ‹©ä¸åŒç«¯å£
            if server_type.upper() == "GPU":
                port = RESOURCE_MONITOR_GPU_PORT
            else:
                port = RESOURCE_MONITOR_CPU_PORT
            
            resource_monitor_url = f"{parsed.scheme}://{parsed.hostname}:{port}"
            return resource_monitor_url
        except Exception as e:
            logger.error(f"URLè½¬æ¢å¤±è´¥: {server_url}, é”™è¯¯: {e}")
            return None
    
    async def check_server_resource(self, server_url: str, server_type: str, 
                                  performance_gb: int, model_name: str = None) -> Tuple[bool, Dict[str, Any]]:
        """
        æ£€æŸ¥æœåŠ¡å™¨èµ„æºæ˜¯å¦å……è¶³(ä»…æ¨¡å‹å¹¶å‘æ„ŸçŸ¥)
        
        Args:
            server_url: åŸå§‹æœåŠ¡å™¨URL
            server_type: CPU æˆ– GPU
            performance_gb: éœ€è¦çš„æ€§èƒ½(GB)
            model_name: æ¨¡å‹åç§°(ç”¨äºå¹¶å‘æ£€æµ‹)
            
        Returns:
            (is_sufficient, resource_info): èµ„æºæ˜¯å¦å……è¶³å’Œè¯¦ç»†ä¿¡æ¯
        """
        # 1. æ¨¡å‹å¹¶å‘æ£€æµ‹
        if model_name and self._should_skip_resource_check(server_url, model_name):
            self.logger.info(f"è·³è¿‡èµ„æºæ£€æŸ¥: {server_url} æ¨¡å‹ {model_name} å¯èƒ½æ­£åœ¨ä½¿ç”¨ä¸­")
            return True, {"skipped": True, "reason": "same_model_concurrent"}
        
        # 2. ç›´æ¥è¿›è¡Œèµ„æºæ£€æŸ¥
        resource_monitor_url = self._convert_url_to_resource_monitor(server_url, server_type)
        if not resource_monitor_url:
            raise Exception(f"æ— æ³•è½¬æ¢èµ„æºç›‘æ§URL: {server_url}")
        
        try:
            async with httpx.AsyncClient(timeout=10) as client:
                # è°ƒç”¨èµ„æºæ£€æŸ¥æ¥å£
                check_url = f"{resource_monitor_url}/resource-check"
                payload = {
                    "type": server_type,
                    "performance": performance_gb
                }
                
                port = RESOURCE_MONITOR_GPU_PORT if server_type.upper() == "GPU" else RESOURCE_MONITOR_CPU_PORT
                self.logger.info(f"ğŸ” è°ƒç”¨èµ„æºç›‘æ§æœåŠ¡: {check_url} (ç«¯å£: {port})")
                self.logger.info(f"ğŸ“‹ æ£€æŸ¥å‚æ•°: ç±»å‹={server_type}, éœ€æ±‚={performance_gb}GB, æ¨¡å‹={model_name}")
                
                response = await client.post(
                    check_url,
                    json=payload,
                    headers={'Content-Type': 'application/json'}
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if result.get('status') == 'success':
                        data = result.get('data', {})
                        is_sufficient = data.get('sufficient', False)
                        
                        # è¯¦ç»†è®°å½•èµ„æºä¿¡æ¯
                        available_gb = data.get('available_gb', 0)
                        total_gb = data.get('total_gb', 0)
                        usage_percent = data.get('usage_percent', 0)
                        
                        self.logger.info(f"ğŸ“Š èµ„æºç›‘æ§å“åº”: æœåŠ¡å™¨={server_url}")
                        self.logger.info(f"   â”œâ”€ ç±»å‹: {server_type}")
                        self.logger.info(f"   â”œâ”€ æ€»å®¹é‡: {total_gb:.1f}GB")
                        self.logger.info(f"   â”œâ”€ å¯ç”¨å®¹é‡: {available_gb:.1f}GB")
                        self.logger.info(f"   â”œâ”€ ä½¿ç”¨ç‡: {usage_percent:.1f}%")
                        self.logger.info(f"   â”œâ”€ æ¨¡å‹éœ€æ±‚: {performance_gb}GB")
                        self.logger.info(f"   â””â”€ èµ„æºå……è¶³: {'âœ… æ˜¯' if is_sufficient else 'âŒ å¦'}")
                        
                        # è®°å½•æ¨¡å‹ä½¿ç”¨å†å²
                        if model_name:
                            self._track_model_usage(server_url, model_name)
                        
                        return is_sufficient, data
                    else:
                        error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
                        self.logger.warning(f"èµ„æºæ£€æŸ¥å¤±è´¥: {error_msg}")
                        return False, {"error": error_msg}
                else:
                    error_msg = f"èµ„æºç›‘æ§æœåŠ¡è¿”å›é”™è¯¯çŠ¶æ€ç : {response.status_code}"
                    logger.warning(error_msg)
                    return False, {"error": error_msg}
                    
        except httpx.TimeoutException:
            error_msg = f"èµ„æºç›‘æ§æœåŠ¡è¶…æ—¶: {resource_monitor_url}"
            logger.warning(error_msg)
            return False, {"error": error_msg}
            
        except httpx.RequestError as e:
            error_msg = f"èµ„æºç›‘æ§æœåŠ¡è¿æ¥å¤±è´¥: {str(e)}"
            logger.warning(error_msg)
            return False, {"error": error_msg}
            
        except Exception as e:
            error_msg = f"èµ„æºæ£€æŸ¥å¼‚å¸¸: {str(e)}"
            logger.error(error_msg)
            return False, {"error": error_msg}
    
    def get_model_usage_stats(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯"""
        current_time = time.time()
        active_usage_count = 0
        
        for timestamp in self._model_usage_history.values():
            if (current_time - timestamp) < MODEL_USAGE_WINDOW:
                active_usage_count += 1
        
        return {
            'total_model_usage_entries': len(self._model_usage_history),
            'active_usage_entries': active_usage_count,
            'same_model_interval': SAME_MODEL_INTERVAL,
            'model_usage_window': MODEL_USAGE_WINDOW
        }
    
    def clear_model_usage_history(self):
        """æ¸…ç©ºæ¨¡å‹ä½¿ç”¨å†å²"""
        self._model_usage_history.clear()
        self.logger.info("å·²æ¸…ç©ºæ¨¡å‹ä½¿ç”¨å†å²")
    
    def get_config(self) -> Dict[str, Any]:
        """è·å–é…ç½®ä¿¡æ¯"""
        return {
            'resource_monitor_port': self.resource_monitor_port,
            'same_model_interval': SAME_MODEL_INTERVAL,
            'model_usage_window': MODEL_USAGE_WINDOW
        }
    
    async def get_memory_info(self, server_url: str, server_type: str = "CPU") -> Optional[Dict[str, Any]]:
        """è·å–æœåŠ¡å™¨å†…å­˜ä¿¡æ¯"""
        resource_monitor_url = self._convert_url_to_resource_monitor(server_url, server_type)
        if not resource_monitor_url:
            return None
        
        try:
            async with httpx.AsyncClient(timeout=10) as client:
                response = await client.get(f"{resource_monitor_url}/memory")
                
                if response.status_code == 200:
                    result = response.json()
                    if result.get('status') == 'success':
                        return result.get('data')
                        
        except Exception as e:
            logger.warning(f"è·å–å†…å­˜ä¿¡æ¯å¤±è´¥: {server_url}, é”™è¯¯: {e}")
        
        return None
    
    async def get_gpu_memory_info(self, server_url: str, server_type: str = "GPU") -> Optional[Dict[str, Any]]:
        """è·å–æœåŠ¡å™¨GPUæ˜¾å­˜ä¿¡æ¯"""
        resource_monitor_url = self._convert_url_to_resource_monitor(server_url, server_type)
        if not resource_monitor_url:
            return None
        
        try:
            async with httpx.AsyncClient(timeout=10) as client:
                response = await client.get(f"{resource_monitor_url}/gpu-memory")
                
                if response.status_code == 200:
                    result = response.json()
                    if result.get('status') == 'success':
                        return result.get('data')
                        
        except Exception as e:
            logger.warning(f"è·å–GPUæ˜¾å­˜ä¿¡æ¯å¤±è´¥: {server_url}, é”™è¯¯: {e}")
        
        return None

# å…¨å±€èµ„æºç›‘æ§å®¢æˆ·ç«¯å®ä¾‹
resource_monitor_client = ResourceMonitorClient()
