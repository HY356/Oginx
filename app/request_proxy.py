"""
è¯·æ±‚ä»£ç†æ¨¡å—
"""

import httpx
import asyncio
import uuid
import time
from typing import Dict, Any, Optional, List
from fastapi import HTTPException
from fastapi.responses import StreamingResponse
try:
    from .load_balancer import load_balancer
    from .logging_manager import logging_manager
    from .resource_monitor_client import resource_monitor_client
except ImportError:
    from app.load_balancer import load_balancer
    from app.logging_manager import logging_manager
    from app.resource_monitor_client import resource_monitor_client
import logging
import json

logger = logging.getLogger(__name__)

class RequestProxy:
    """è¯·æ±‚ä»£ç†å™¨"""
    
    def __init__(self):
        self.client_timeout = 300.0  # 5åˆ†é’Ÿè¶…æ—¶
    
    async def proxy_request(self, method: str, path: str, 
                          model_name: str = None, 
                          headers: Dict[str, str] = None,
                          json_data: Dict[str, Any] = None,
                          params: Dict[str, str] = None) -> Dict[str, Any]:
        """ä»£ç†è¯·æ±‚åˆ°åç«¯æœåŠ¡å™¨"""
        
        request_id = str(uuid.uuid4())
        start_time = time.time()
        
        try:
            # å¦‚æœæ˜¯æ¨¡å‹ç›¸å…³çš„è¯·æ±‚ï¼Œéœ€è¦è¿›è¡Œè´Ÿè½½å‡è¡¡
            if model_name and path.startswith('/api/'):
                return await self._proxy_model_request(
                    request_id, method, path, model_name, 
                    headers, json_data, params, start_time
                )
            else:
                # éæ¨¡å‹è¯·æ±‚ï¼Œè¿”å›é”™è¯¯
                raise HTTPException(status_code=404, detail="Endpoint not found")
                
        except HTTPException:
            raise
        except Exception as e:
            logging_manager.log_error(e, request_id=request_id)
            raise HTTPException(status_code=500, detail=f"ä»£ç†è¯·æ±‚å¤±è´¥: {str(e)}")
    
    async def _proxy_model_request(self, request_id: str, method: str, path: str,
                                 model_name: str, headers: Dict[str, str],
                                 json_data: Dict[str, Any], params: Dict[str, str],
                                 start_time: float) -> Dict[str, Any]:
        """ä»£ç†æ¨¡å‹ç›¸å…³è¯·æ±‚ - æ™ºèƒ½å›é€€ç­–ç•¥"""
        
        # è·å–æ‰€æœ‰å¯ç”¨æœåŠ¡å™¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        all_servers = load_balancer.get_servers_for_model(model_name)
        if not all_servers:
            raise HTTPException(
                status_code=503, 
                detail=f"è™šæ‹Ÿæ¨¡å‹ {model_name} æ²¡æœ‰é…ç½®çš„æœåŠ¡å™¨"
            )
        
        # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„å¹¶åœ¨ç»„å†…åº”ç”¨æƒé‡é€»è¾‘
        priority_groups = {}
        for server in all_servers:
            priority = server['priority']
            if priority not in priority_groups:
                priority_groups[priority] = []
            priority_groups[priority].append(server)
        
        # æŒ‰ä¼˜å…ˆçº§é¡ºåºå°è¯•ï¼Œåœ¨æ¯ä¸ªä¼˜å…ˆçº§å†…æŒ‰æƒé‡æ’åºå°è¯•
        last_error = None
        total_attempts = 0
        total_servers = sum(len(servers) for servers in priority_groups.values())
        
        logger.info(f"[{request_id}] å¼€å§‹è½®è¯¢æ‰€æœ‰æœåŠ¡å™¨: æ¨¡å‹ {model_name}, å…± {total_servers} ä¸ªæœåŠ¡å™¨, {len(priority_groups)} ä¸ªä¼˜å…ˆçº§")
        
        for priority in sorted(priority_groups.keys()):
            group_servers = priority_groups[priority]
            
            # åœ¨åŒä¸€ä¼˜å…ˆçº§å†…ï¼ŒæŒ‰æƒé‡æ’åºï¼ˆæƒé‡é«˜çš„ä¼˜å…ˆå°è¯•ï¼‰
            # ä½†ä»ç„¶ä¼šå°è¯•è¯¥ä¼˜å…ˆçº§çš„æ‰€æœ‰æœåŠ¡å™¨
            weighted_servers = self._get_weighted_server_order(group_servers)
            
            logger.info(f"[{request_id}] å¼€å§‹å°è¯•ä¼˜å…ˆçº§ {priority} çš„ {len(weighted_servers)} ä¸ªæœåŠ¡å™¨")
            
            for server in weighted_servers:
                total_attempts += 1
                try:
                    logger.info(f"[{request_id}] å°è¯•æœåŠ¡å™¨ {total_attempts}/{total_servers}: {server['server_url']} (ä¼˜å…ˆçº§: {priority}, æƒé‡: {server['weight']})")
                    return await self._try_single_server(
                        request_id, method, path, model_name, server,
                        headers, json_data, params, start_time, total_attempts
                    )
                except Exception as e:
                    last_error = e
                    logger.warning(f"[{request_id}] æœåŠ¡å™¨è¯·æ±‚å¤±è´¥ {total_attempts}/{total_servers}: {model_name} -> {server['actual_model_name']} (æœåŠ¡å™¨: {server['server_url']}, ä¼˜å…ˆçº§: {priority}, æƒé‡: {server['weight']}, é”™è¯¯: {str(e)})")
                    continue
            
            logger.warning(f"[{request_id}] ä¼˜å…ˆçº§ {priority} çš„æ‰€æœ‰ {len(weighted_servers)} ä¸ªæœåŠ¡å™¨éƒ½å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¼˜å…ˆçº§")
        
        # æ‰€æœ‰æœåŠ¡å™¨éƒ½å¤±è´¥äº† - å®Œæ•´è½®è¯¢ç»“æŸ
        logger.error(f"[{request_id}] è½®è¯¢ç»“æŸ: æ¨¡å‹ {model_name} çš„æ‰€æœ‰ {total_servers} ä¸ªæœåŠ¡å™¨éƒ½ä¸å¯ç”¨ï¼Œæœ€åé”™è¯¯: {str(last_error)}")
        raise HTTPException(
            status_code=503,
            detail=f"è™šæ‹Ÿæ¨¡å‹ {model_name} çš„æ‰€æœ‰ {total_servers} ä¸ªæœåŠ¡å™¨éƒ½ä¸å¯ç”¨ï¼Œå·²å®Œæˆå®Œæ•´è½®è¯¢: {str(last_error)}"
        )
        
    
    async def _try_single_server(self, request_id: str, method: str, path: str,
                               model_name: str, server: Dict[str, Any],
                               headers: Dict[str, str], json_data: Dict[str, Any],
                               params: Dict[str, str], start_time: float, attempt: int) -> Dict[str, Any]:
        """å°è¯•å•ä¸ªæœåŠ¡å™¨"""
        
        server_url = server['server_url']
        actual_model_name = server['actual_model_name']
        
        # å¤åˆ¶json_dataä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        request_json = json_data.copy() if json_data else None
        if request_json and 'model' in request_json:
            request_json['model'] = actual_model_name
        
        # è®°å½•è¯·æ±‚å¼€å§‹
        logger.info(f"[{request_id}] å¼€å§‹è¯·æ±‚è™šæ‹Ÿæ¨¡å‹ '{model_name}' -> å®é™…æ¨¡å‹ '{actual_model_name}' (æœåŠ¡å™¨: {server_url}, å°è¯•: {attempt})")
        logging_manager.log_request(
            request_id, method, f"{server_url}{path}",
            model_name=model_name, server_url=server_url,
            message=f"å°è¯•æœåŠ¡å™¨ {attempt} - å¼€å§‹è¯·æ±‚"
        )
        
        # å…ˆè¿›è¡Œå¿«é€Ÿå¥åº·æ£€æŸ¥
        is_healthy, health_time = await load_balancer.check_server_health(server_url, actual_model_name)
        if not is_healthy:
            raise Exception(f"æœåŠ¡å™¨å¥åº·æ£€æŸ¥å¤±è´¥: {server_url}")
        
        # è¿›è¡Œèµ„æºå……è¶³æ€§æ£€æŸ¥
        # æ£€æŸ¥æ˜¯å¦é…ç½®è·³è¿‡èµ„æºæ£€æµ‹
        skip_resource_check = server.get('skip_resource_check', False)
        
        if skip_resource_check:
            logger.info(f"[{request_id}] â­ï¸ é…ç½®è·³è¿‡èµ„æºæ£€æŸ¥: {server_url} æ¨¡å‹ {model_name} (skip_resource_check=True)")
        else:
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            if 'type' not in server or 'performance' not in server:
                raise Exception(f"æœåŠ¡å™¨é…ç½®ç¼ºå°‘å¿…éœ€å­—æ®µ: {server_url}")
            
            server_type = server['type']
            performance = server['performance']
            
            logger.info(f"[{request_id}] ğŸ“Š èµ„æºæ£€æŸ¥å¼€å§‹: æœåŠ¡å™¨ {server_url} (ç±»å‹: {server_type}, æ¨¡å‹éœ€æ±‚: {performance}GB)")
            
            is_sufficient, resource_info = await resource_monitor_client.check_server_resource(
                server_url, server_type, performance, model_name
            )
            
            # è¯¦ç»†çš„èµ„æºä¿¡æ¯æ—¥å¿—
            available_gb = resource_info.get('available_gb', 0)
            total_gb = resource_info.get('total_gb', 0)
            usage_percent = resource_info.get('usage_percent', 0)
            
            if resource_info.get('skipped', False):
                logger.info(f"[{request_id}] â­ï¸ è·³è¿‡èµ„æºæ£€æŸ¥: {server_url} æ¨¡å‹ {model_name} å¯èƒ½æ­£åœ¨ä½¿ç”¨ä¸­ (5åˆ†é’Ÿå†…å·²è°ƒç”¨)")
            else:
                logger.info(f"[{request_id}] ğŸ“ˆ èµ„æºçŠ¶æ€: {server_url} | ç±»å‹: {server_type} | æ€»å®¹é‡: {total_gb:.1f}GB | å¯ç”¨: {available_gb:.1f}GB | ä½¿ç”¨ç‡: {usage_percent:.1f}% | éœ€æ±‚: {performance}GB")
            
            if not is_sufficient and not resource_info.get('skipped', False):
                error_msg = f"æœåŠ¡å™¨èµ„æºä¸è¶³: {server_url} (ç±»å‹: {server_type}, éœ€æ±‚: {performance}GB, å¯ç”¨: {available_gb:.1f}GB/{total_gb:.1f}GB, ä½¿ç”¨ç‡: {usage_percent:.1f}%)"
                logger.warning(f"[{request_id}] âŒ {error_msg}")
                raise Exception(error_msg)
            elif is_sufficient:
                logger.info(f"[{request_id}] âœ… èµ„æºå……è¶³: {server_url} æ»¡è¶³ {model_name} éœ€æ±‚ ({performance}GB), é€‰æ‹©æ­¤æœåŠ¡å™¨")
        
        try:
            async with httpx.AsyncClient(timeout=self.client_timeout) as client:
                # æ¸…ç†å’Œå‡†å¤‡headers
                clean_headers = {}
                if headers:
                    for key, value in headers.items():
                        if key.lower() not in ['content-length', 'transfer-encoding', 'connection']:
                            clean_headers[key] = value
                
                # æ„å»ºè¯·æ±‚
                request_kwargs = {
                    'method': method,
                    'url': f"{server_url}{path}",
                    'headers': clean_headers,
                    'params': params or {}
                }
                
                if request_json:
                    request_kwargs['json'] = request_json
                
                # å‘é€è¯·æ±‚
                response = await client.request(**request_kwargs)
                response_time = time.time() - start_time
                
                # è®°å½•å“åº”
                logger.info(f"[{request_id}] è¯·æ±‚æˆåŠŸ: {model_name} -> {actual_model_name} (æœåŠ¡å™¨: {server_url}, çŠ¶æ€: {response.status_code}, è€—æ—¶: {response_time:.3f}s)")
                logging_manager.log_request(
                    request_id, method, f"{server_url}{path}",
                    model_name=model_name, server_url=server_url,
                    response_time=response_time, status_code=response.status_code,
                    message=f"å°è¯•æœåŠ¡å™¨ {attempt} - è¯·æ±‚å®Œæˆ"
                )
                
                # æ£€æŸ¥HTTPçŠ¶æ€ç 
                if response.status_code == 404:
                    raise Exception(f"æ¨¡å‹æˆ–æ¥å£ä¸å­˜åœ¨: {response.status_code}")
                elif response.status_code == 503:
                    raise Exception(f"æœåŠ¡ä¸å¯ç”¨: {response.status_code}")
                elif response.status_code >= 500:
                    raise Exception(f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {response.status_code}")
                elif response.status_code >= 400:
                    # 4xxé”™è¯¯ä¹Ÿéœ€è¦é‡è¯•å…¶ä»–æœåŠ¡å™¨ï¼Œå› ä¸ºä¸åŒæœåŠ¡å™¨å¯èƒ½æœ‰ä¸åŒçš„æ¨¡å‹
                    logger.warning(f"[{request_id}] æœåŠ¡å™¨è¿”å›4xxé”™è¯¯ï¼Œå°†å°è¯•ä¸‹ä¸€ä¸ªæœåŠ¡å™¨: {server_url} (çŠ¶æ€ç : {response.status_code})")
                    raise Exception(f"å®¢æˆ·ç«¯é”™è¯¯ {response.status_code}: {response.text}")
                
                # è®°å½•æ€§èƒ½
                logging_manager.log_performance(
                    f"{method} {path}", response_time,
                    server_url=server_url, model_name=model_name,
                    request_id=request_id
                )
                
                # å¤„ç†å“åº”æ•°æ®
                try:
                    response_data = response.json()
                    
                    # å°†å®é™…æ¨¡å‹åæ›¿æ¢å›è™šæ‹Ÿæ¨¡å‹å
                    if isinstance(response_data, dict):
                        if 'model' in response_data:
                            response_data['model'] = model_name
                        elif 'models' in response_data:
                            # å¤„ç† /api/tags å“åº”
                            for model_info in response_data['models']:
                                if model_info.get('name') == actual_model_name:
                                    model_info['name'] = model_name
                    
                    # è¯·æ±‚æˆåŠŸï¼Œå¢åŠ æœåŠ¡å™¨è®¡æ•°
                    from .database import db_manager
                    db_manager.increment_server_count(server['id'])
                    
                    logger.info(f"è¯·æ±‚æˆåŠŸ: {server_url} -> {actual_model_name} (å°è¯• {attempt})")
                    return response_data
                    
                except json.JSONDecodeError:
                    # å¦‚æœä¸æ˜¯JSONå“åº”ï¼Œç›´æ¥è¿”å›æ–‡æœ¬
                    return {"response": response.text}
                
        except httpx.TimeoutException:
            error_msg = f"è¯·æ±‚è¶…æ—¶: {server_url}{path}"
            logging_manager.log_error(
                Exception(error_msg), request_id=request_id,
                server_url=server_url, model_name=model_name
            )
            raise Exception(error_msg)
            
        except httpx.RequestError as e:
            error_msg = f"è¿æ¥é”™è¯¯: {str(e)}"
            logging_manager.log_error(
                e, request_id=request_id,
                server_url=server_url, model_name=model_name
            )
            raise Exception(error_msg)
        
        except HTTPException:
            # HTTPExceptionéœ€è¦ç›´æ¥æŠ›å‡ºï¼Œä¸è¿›è¡Œé‡è¯•
            raise
        
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸è®°å½•æ—¥å¿—åé‡æ–°æŠ›å‡º
            logging_manager.log_error(
                e, request_id=request_id,
                server_url=server_url, model_name=model_name
            )
            raise
    
    def _get_weighted_server_order(self, servers: List[Dict]) -> List[Dict]:
        """è·å–æŒ‰æƒé‡æ’åºçš„æœåŠ¡å™¨åˆ—è¡¨ï¼ˆæƒé‡é«˜çš„ä¼˜å…ˆï¼Œä½†ä¼šå°è¯•æ‰€æœ‰æœåŠ¡å™¨ï¼‰"""
        if not servers:
            return []
        
        if len(servers) == 1:
            return servers
        
        # æŒ‰æƒé‡é™åºæ’åºï¼Œæƒé‡ç›¸åŒæ—¶ä¿æŒåŸé¡ºåº
        return sorted(servers, key=lambda x: x['weight'], reverse=True)
    
    async def proxy_streaming_request(self, method: str, path: str,
                                    model_name: str, headers: Dict[str, str] = None,
                                    json_data: Dict[str, Any] = None) -> StreamingResponse:
        """ä»£ç†æµå¼è¯·æ±‚ - æ™ºèƒ½å›é€€ç­–ç•¥"""
        
        request_id = str(uuid.uuid4())
        
        # è·å–æ‰€æœ‰å¯ç”¨æœåŠ¡å™¨
        all_servers = load_balancer.get_servers_for_model(model_name)
        if not all_servers:
            raise HTTPException(
                status_code=503,
                detail=f"è™šæ‹Ÿæ¨¡å‹ {model_name} æ²¡æœ‰é…ç½®çš„æœåŠ¡å™¨"
            )
        
        # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„å¹¶åœ¨ç»„å†…åº”ç”¨æƒé‡é€»è¾‘
        priority_groups = {}
        for server in all_servers:
            priority = server['priority']
            if priority not in priority_groups:
                priority_groups[priority] = []
            priority_groups[priority].append(server)
        
        # æŒ‰ä¼˜å…ˆçº§é¡ºåºå°è¯•ï¼Œåœ¨æ¯ä¸ªä¼˜å…ˆçº§å†…æŒ‰æƒé‡æ’åºå°è¯•
        total_attempts = 0
        last_error = None
        total_servers = sum(len(servers) for servers in priority_groups.values())
        
        logger.info(f"[{request_id}] å¼€å§‹è½®è¯¢æ‰€æœ‰æœåŠ¡å™¨è¿›è¡Œæµå¼è¯·æ±‚: æ¨¡å‹ {model_name}, å…± {total_servers} ä¸ªæœåŠ¡å™¨, {len(priority_groups)} ä¸ªä¼˜å…ˆçº§")
        
        for priority in sorted(priority_groups.keys()):
            group_servers = priority_groups[priority]
            weighted_servers = self._get_weighted_server_order(group_servers)
            
            logger.info(f"[{request_id}] å¼€å§‹å°è¯•ä¼˜å…ˆçº§ {priority} çš„ {len(weighted_servers)} ä¸ªæœåŠ¡å™¨ï¼ˆæµå¼è¯·æ±‚ï¼‰")
            
            for server in weighted_servers:
                total_attempts += 1
                try:
                    # å…ˆè¿›è¡Œå¥åº·æ£€æŸ¥
                    is_healthy, _ = await load_balancer.check_server_health(
                        server['server_url'], server['actual_model_name']
                    )
                    if not is_healthy:
                        logger.warning(f"[{request_id}] æµå¼è¯·æ±‚è·³è¿‡ä¸å¥åº·çš„æœåŠ¡å™¨ {total_attempts}/{total_servers}: {model_name} -> {server['actual_model_name']} (æœåŠ¡å™¨: {server['server_url']}, ä¼˜å…ˆçº§: {priority})")
                        last_error = Exception(f"æœåŠ¡å™¨å¥åº·æ£€æŸ¥å¤±è´¥: {server['server_url']}")
                        continue
                    
                    # è¿›è¡Œèµ„æºå……è¶³æ€§æ£€æŸ¥
                    # æ£€æŸ¥æ˜¯å¦é…ç½®è·³è¿‡èµ„æºæ£€æµ‹
                    skip_resource_check = server.get('skip_resource_check', False)
                    
                    if skip_resource_check:
                        logger.info(f"[{request_id}] â­ï¸ æµå¼è¯·æ±‚é…ç½®è·³è¿‡èµ„æºæ£€æŸ¥: {server['server_url']} æ¨¡å‹ {model_name} (skip_resource_check=True)")
                    else:
                        server_type = server.get('type', 'CPU')
                        performance = server.get('performance', 8)
                        
                        logger.info(f"[{request_id}] ğŸ“Š æµå¼è¯·æ±‚èµ„æºæ£€æŸ¥: æœåŠ¡å™¨ {server['server_url']} (ç±»å‹: {server_type}, æ¨¡å‹éœ€æ±‚: {performance}GB)")
                        
                        is_sufficient, resource_info = await resource_monitor_client.check_server_resource(
                            server['server_url'], server_type, performance, model_name
                        )
                        
                        # è¯¦ç»†çš„èµ„æºä¿¡æ¯æ—¥å¿—
                        available_gb = resource_info.get('available_gb', 0)
                        total_gb = resource_info.get('total_gb', 0)
                        usage_percent = resource_info.get('usage_percent', 0)
                        
                        if resource_info.get('skipped', False):
                            logger.info(f"[{request_id}] â­ï¸ æµå¼è¯·æ±‚è·³è¿‡èµ„æºæ£€æŸ¥: {server['server_url']} æ¨¡å‹ {model_name} å¯èƒ½æ­£åœ¨ä½¿ç”¨ä¸­ (5åˆ†é’Ÿå†…å·²è°ƒç”¨)")
                        else:
                            logger.info(f"[{request_id}] ğŸ“ˆ æµå¼è¯·æ±‚èµ„æºçŠ¶æ€: {server['server_url']} | ç±»å‹: {server_type} | æ€»å®¹é‡: {total_gb:.1f}GB | å¯ç”¨: {available_gb:.1f}GB | ä½¿ç”¨ç‡: {usage_percent:.1f}% | éœ€æ±‚: {performance}GB")
                        
                        if not is_sufficient and not resource_info.get('skipped', False):
                            error_msg = f"æœåŠ¡å™¨èµ„æºä¸è¶³: {server['server_url']} (ç±»å‹: {server_type}, éœ€æ±‚: {performance}GB, å¯ç”¨: {available_gb:.1f}GB/{total_gb:.1f}GB, ä½¿ç”¨ç‡: {usage_percent:.1f}%)"
                            logger.warning(f"[{request_id}] âŒ æµå¼è¯·æ±‚è·³è¿‡èµ„æºä¸è¶³çš„æœåŠ¡å™¨ {total_attempts}/{total_servers}: {error_msg}")
                            last_error = Exception(error_msg)
                            continue
                        elif is_sufficient:
                            logger.info(f"[{request_id}] âœ… æµå¼è¯·æ±‚èµ„æºå……è¶³: {server['server_url']} æ»¡è¶³ {model_name} éœ€æ±‚ ({performance}GB), é€‰æ‹©æ­¤æœåŠ¡å™¨")
                    
                    # ä½¿ç”¨è¿™ä¸ªæœåŠ¡å™¨è¿›è¡Œæµå¼ä¼ è¾“
                    logger.info(f"[{request_id}] å°è¯•æµå¼ä¼ è¾“ {total_attempts}/{total_servers}: {model_name} -> {server['actual_model_name']} (æœåŠ¡å™¨: {server['server_url']}, ä¼˜å…ˆçº§: {priority}, æƒé‡: {server['weight']})")
                    return await self._create_streaming_response(
                        request_id, method, path, model_name, server, headers, json_data, total_attempts
                    )
                    
                except Exception as e:
                    last_error = e
                    logger.warning(f"[{request_id}] æµå¼è¯·æ±‚æœåŠ¡å™¨å¤±è´¥ {total_attempts}/{total_servers}: {model_name} -> {server['actual_model_name']} (æœåŠ¡å™¨: {server['server_url']}, ä¼˜å…ˆçº§: {priority}, æƒé‡: {server['weight']}, é”™è¯¯: {str(e)})")
                    continue
            
            logger.warning(f"[{request_id}] ä¼˜å…ˆçº§ {priority} çš„æ‰€æœ‰ {len(weighted_servers)} ä¸ªæœåŠ¡å™¨éƒ½å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¼˜å…ˆçº§")
        
        # æ‰€æœ‰æœåŠ¡å™¨éƒ½å¤±è´¥ - å®Œæ•´è½®è¯¢ç»“æŸ
        logger.error(f"[{request_id}] æµå¼è¯·æ±‚è½®è¯¢ç»“æŸ: æ¨¡å‹ {model_name} çš„æ‰€æœ‰ {total_servers} ä¸ªæœåŠ¡å™¨éƒ½ä¸å¯ç”¨ï¼Œæœ€åé”™è¯¯: {str(last_error)}")
        raise HTTPException(
            status_code=503,
            detail=f"è™šæ‹Ÿæ¨¡å‹ {model_name} çš„æ‰€æœ‰ {total_servers} ä¸ªæœåŠ¡å™¨éƒ½ä¸å¯ç”¨äºæµå¼è¯·æ±‚ï¼Œå·²å®Œæˆå®Œæ•´è½®è¯¢: {str(last_error)}"
        )
    
    async def _create_streaming_response(self, request_id: str, method: str, path: str,
                                       model_name: str, server: Dict[str, Any],
                                       headers: Dict[str, str], json_data: Dict[str, Any],
                                       attempt: int) -> StreamingResponse:
        """åˆ›å»ºæµå¼å“åº”"""
        
        server_url = server['server_url']
        actual_model_name = server['actual_model_name']
        
        # å¤åˆ¶json_dataä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        request_json = json_data.copy() if json_data else None
        if request_json and 'model' in request_json:
            request_json['model'] = actual_model_name
        
        async def stream_generator():
            try:
                logger.info(f"[{request_id}] å¼€å§‹ä»£ç†è¯·æ±‚: {method} {path} (æ¨¡å‹: {model_name}) (å°è¯• {attempt})")
                
                async with httpx.AsyncClient(timeout=self.client_timeout) as client:
                    # æ¸…ç†headers
                    clean_headers = {}
                    if headers:
                        for key, value in headers.items():
                            if key.lower() not in ['content-length', 'transfer-encoding', 'connection']:
                                clean_headers[key] = value
                    
                    async with client.stream(
                        method, f"{server_url}{path}",
                        headers=clean_headers,
                        json=request_json
                    ) as response:
                        
                        if response.status_code == 404:
                            error_msg = f"æ¨¡å‹æˆ–æ¥å£ä¸å­˜åœ¨: {response.status_code}"
                            logger.warning(f"[{request_id}] æœåŠ¡å™¨è¿”å›404ï¼Œå°†å°è¯•ä¸‹ä¸€ä¸ªæœåŠ¡å™¨: {server_url}")
                            raise Exception(error_msg)
                        elif response.status_code >= 500:
                            error_msg = f"æœåŠ¡å™¨é”™è¯¯: {response.status_code}"
                            logger.warning(f"[{request_id}] æœåŠ¡å™¨è¿”å›5xxé”™è¯¯ï¼Œå°†å°è¯•ä¸‹ä¸€ä¸ªæœåŠ¡å™¨: {server_url}")
                            raise Exception(error_msg)
                        elif response.status_code >= 400:
                            error_text = await response.aread()
                            error_msg = f"å®¢æˆ·ç«¯é”™è¯¯ {response.status_code}: {error_text.decode()}"
                            logger.warning(f"[{request_id}] æœåŠ¡å™¨è¿”å›4xxé”™è¯¯ï¼Œå°†å°è¯•ä¸‹ä¸€ä¸ªæœåŠ¡å™¨: {server_url}")
                            raise Exception(error_msg)
                        
                        # è¯·æ±‚æˆåŠŸï¼Œå¢åŠ æœåŠ¡å™¨è®¡æ•°
                        from .database import db_manager
                        db_manager.increment_server_count(server['id'])
                        
                        logger.info(f"æµå¼è¯·æ±‚æˆåŠŸå»ºç«‹: {server_url} -> {actual_model_name}")
                        
                        async for chunk in response.aiter_text():
                            if chunk.strip():
                                try:
                                    # å°è¯•è§£æJSONå¹¶æ›¿æ¢æ¨¡å‹å
                                    data = json.loads(chunk)
                                    if isinstance(data, dict) and 'model' in data:
                                        data['model'] = model_name
                                    yield json.dumps(data, ensure_ascii=False) + '\n'
                                except json.JSONDecodeError:
                                    # å¦‚æœä¸æ˜¯JSONï¼Œç›´æ¥è¿”å›
                                    yield chunk
                                    
            except Exception as e:
                error_msg = f"æµå¼è¯·æ±‚å¼‚å¸¸: {str(e)}"
                logger.error(error_msg)
                logging_manager.log_error(
                    e, request_id=request_id,
                    server_url=server_url, model_name=model_name
                )
                yield f"data: {json.dumps({'error': error_msg}, ensure_ascii=False)}\n\n"
        
        return StreamingResponse(
            stream_generator(),
            media_type="text/plain",
            headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
        )

# å…¨å±€è¯·æ±‚ä»£ç†å®ä¾‹
request_proxy = RequestProxy()
